import sys

import autogen
import sys
sys.path.append("/home/kali/Agent/Agent-main-master/")
sys.path.append("/home/kali/Agent/Agent-main-master/config")
sys.path.append("/home/kali/Agent/Agent-main-master/contant")
from config.llmConfig import LLM_CONFIG, LLM_CONFIG_DEFAULT
from typing_extensions import Annotated

from autogen import AssistantAgent, UserProxyAgent
from ProxyAgent.MyRetrieveUserProxyAgent import MyRetrieveUserProxyAgent
from tool import network_scanTool, scanTool, searchMatchingModulesTool,\
    moduleTool,attackTool,meterpreter
config_list = autogen.config_list_from_json("api_config.json")
print("LLM models: ", [config_list[i]["model"] for i in range(len(config_list))])
api_key = "sk-proj-AmJg3kq457E8EXaNilmZT3BlbkFJxAlW57CiKjgdiaiHIJrG"
CONFIG_LLM = [{"model": "gpt-3.5-turbo", "api_key": api_key}]

def termination_msg(x):
    return isinstance(x, dict) and "TERMINATE" == str(x.get("content", ""))[-9:].upper()


llm_config = {"config_list": config_list[0], "timeout": 60, "temperature": 0.8, "seed": 1234}

boss = UserProxyAgent(
    name="Boss",
    is_termination_msg=termination_msg,
    human_input_mode="ALWAYS",
    code_execution_config=False,  # we don't want to execute code in this case.
    default_auto_reply="如果任务已完成，请回复“TERMINATE”。",
    description="提出问题并根据其他代理的反馈去执行任务。",
)

pentest_aid = MyRetrieveUserProxyAgent(
    name="Pentest_Assistant",
    is_termination_msg=termination_msg,
    human_input_mode="NEVER",
    default_auto_reply="如果任务已完成，请回复“TERMINATE”。",
    max_consecutive_auto_reply=3,
    retrieve_config={
        "task": "qa",
        "docs_path": "/home/kali/Agent/data/pentest_output.json",  # 修改路径以指向渗透测试相关的文档
        "chunk_token_size": 1000,
        "model": config_list[0]["model"],
        "get_or_create": True,
    },
    code_execution_config=False,  # 不执行代码
    description="具有额外内容检索能力的助理，负责解决渗透测试相关问题。",
)


pentester = AssistantAgent(
    name="Penetration_Test_Engineer",
    is_termination_msg=termination_msg,
    system_message="你是一名渗透测试工程师。你的工作是进行安全评估和渗透测试。提供进行各种安全测试的详细步骤、命令和代码片段。完成所有操作后，最后回复“TERMINATE”。",
    llm_config=LLM_CONFIG,
    description="渗透测试工程师，可以进行安全评估和渗透测试，并提供详细的说明和代码。",
)


reviewer = AssistantAgent(
    name="Pentest_Reviewer",
    is_termination_msg=termination_msg,
    system_message=(
        "你是渗透测试审查员。 "
        "您的任务是复习渗透测试知识和流程。 "
        "您应该将任务分解为子任务，并仔细审查每一个子任务。 "
        "为每个子任务提供详细的反馈和改进。 "
        "完成所有操作后，最后回复“TERMINATE”。"
    ),
    llm_config=LLM_CONFIG_DEFAULT,
    description="渗透测试审查员，可以审查渗透测试知识和流程，将任务分解为子任务进行详细审查。",
)

# PROBLEM = "请问漏洞扫描的流程是什么？帮我执行 MS17-010（Eternal blue永恒之蓝）漏洞的自动执行。"
PROBLEM = "在192.168.60.138靶机捕获屏幕"
boss.register_function(
    function_map={
        network_scanTool.name: network_scanTool._run,
        scanTool.name: scanTool._run,
        searchMatchingModulesTool.name: searchMatchingModulesTool._run,
        moduleTool.name: moduleTool._run,
        attackTool.name: attackTool._run,
        meterpreter.name: meterpreter._run,
    }
)
pentester.register_function(
    function_map={
        network_scanTool.name: network_scanTool._run,
        scanTool.name: scanTool._run,
        searchMatchingModulesTool.name: searchMatchingModulesTool._run,
        moduleTool.name: moduleTool._run,
        attackTool.name: attackTool._run,
        meterpreter.name: meterpreter._run,
    }
)

# 初始化
def _reset_agents():
    boss.reset()
    pentest_aid.reset()
    pentester.reset()
    reviewer.reset()


def rag_chat():
    _reset_agents()
    groupchat = autogen.GroupChat(
        agents=[pentest_aid, pentester, reviewer], messages=[], max_round=12, speaker_selection_method="round_robin"
    )
    manager = autogen.GroupChatManager(groupchat=groupchat, llm_config={"config_list": CONFIG_LLM})

    # Start chatting with pentest_aid as this is the user proxy agent.
    pentest_aid.initiate_chat(
        manager,
        message=pentest_aid.message_generator,
        problem=PROBLEM,
        n_results=3,
    )


def norag_chat():
    _reset_agents()
    groupchat = autogen.GroupChat(
        agents=[boss, pentester],
        messages=[],
        max_round=12,
        speaker_selection_method="auto",
        allow_repeat_speaker=False,
    )

    manager = autogen.GroupChatManager(groupchat=groupchat, llm_config={"config_list": CONFIG_LLM})

    # Start chatting with the boss as this is the user proxy agent.
    boss.initiate_chat(
        manager,
        message=PROBLEM,
    )


def call_rag_chat():
    _reset_agents()
    # 在这种情况下，我们将有多个用户代理，并且我们不会启动聊天
    # #使用RAG用户代理。
    # #为了使用RAG用户代理，我们需要将RAG代理封装在一个函数中并调用
    # #它来自其他代理
    def retrieve_content(
        message: Annotated[
            str,
            "Refined message which keeps the original meaning and can be used to retrieve content for code generation and question answering.",
        ],
        n_results: Annotated[int, "number of results"] = 3,
    ) -> str:
        pentest_aid.n_results = n_results  # Set the number of results to be retrieved.
        # Check if we need to update the context.
        update_context_case1, update_context_case2 = pentest_aid._check_update_context(message)
        if (update_context_case1 or update_context_case2) and pentest_aid.update_context:
            pentest_aid.problem = message if not hasattr(pentest_aid, "problem") else pentest_aid.problem
            _, ret_msg = pentest_aid._generate_retrieve_user_reply(message)
        else:
            _context = {"problem": message, "n_results": n_results}
            ret_msg = pentest_aid.message_generator(pentest_aid, None, _context)
        return ret_msg if ret_msg else message

    pentest_aid.human_input_mode = "NEVER"  # Disable human input for pentest_aid since it only retrieves content.

    for caller in [ reviewer]:
        d_retrieve_content = caller.register_for_llm(
            description="retrieve content for code generation and question answering.", api_style="function"
        )(retrieve_content)
    for executor in [boss]:
        executor.register_for_execution()(d_retrieve_content)

    groupchat = autogen.GroupChat(
        agents=[boss, pentester, reviewer],
        messages=[],
        max_round=12,
        speaker_selection_method="auto",
        allow_repeat_speaker=False,
    )

    manager = autogen.GroupChatManager(groupchat=groupchat, llm_config={"config_list": CONFIG_LLM})

    # Start chatting with the boss as this is the user proxy agent.
    boss.initiate_chat(
        manager,
        message=PROBLEM,
    )


if __name__ == '__main__':
    # rag_chat()
    call_rag_chat()

