from langchain_community.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from elasticsearch import Elasticsearch
from langchain_community.vectorstores import ElasticsearchStore
import sys
import autogen
sys.path.append("/home/kali/Agent/Agent-main-master/")
sys.path.append("/home/kali/Agent/Agent-main-master/contant")
sys.path.append("/home/kali/Agent/Agent-main-master/es")
from contant.ESContant import es_url, index_name, embeddings

# 直接传递 API 密钥来初始化 embeddings 对象
api_key = "sk-proj-AmJg3kq457E8EXaNilmZT3BlbkFJxAlW57CiKjgdiaiHIJrG"

#建立客户端
vectorstore = ElasticsearchStore(
    es_url=es_url, index_name=index_name, embedding=embeddings
)
client = Elasticsearch("http://192.168.92.131:9200")

# 判断索引是否存在
if client.indices.exists(index=index_name):
    # 删除索引
    client.indices.delete(index=index_name)
    print(f"Index '{index_name}' deleted successfully.")
else:
    print(f"Index '{index_name}' does not exist.")

    import json

json_file_path = '/home/kali/Agent/Agent-main-master/data/Metasploitable1.json'
with open(json_file_path, 'r', encoding='utf-8') as f:
    document = json.load(f)
print(f"Successfully loaded document with description: {document['description']}")
# Main task description
content = []
metadata = []
main_task_desc = document['description']

# Combine all sub_question_desc into a single string
combined_sub_question_desc = ' '.join(
    [f"{i + 1}. {sub_question.get('sub_task_desc', '')}/n" for i, sub_question in
        enumerate(document['steps'])])

# Create content and metadata lists
content = [combined_sub_question_desc]
metadata = [{"main_task_desc": main_task_desc}]
combined_content_metadata = [
    f"子任务: {content_item} 任务: {metadata_item['main_task_desc']}"
    for content_item, metadata_item in zip(content, metadata)
]

text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
    chunk_size=512,
    chunk_overlap=256,
)

# Create document chunks
docs = text_splitter.create_documents(combined_content_metadata, metadatas=metadata)
print(f"Split document into {len(docs)} passages")
db = vectorstore.from_documents(
    docs,
    embeddings,
    index_name=index_name,
    es_url=es_url
)

if __name__ == '__main__':
    question = '如何获取靶机root权限'
    question_embedding = embeddings.embed_query(question)
    docs = vectorstore.similarity_search(question,k=1)
    print(docs)
