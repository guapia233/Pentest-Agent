import os
import autogen
from util.llm_config import generate_llm_config
from tool import network_scanTool, port_scanTool, web_scanTool, scanTool, msfconsoleTool, searchMatchingModulesTool, moduleTool, attackTool, meterpreter, retrieve_tool
# gpt-3.5-turbo
key = os.environ["OPENAI_API_KEY"]="sk-proj-AmJg3kq457E8EXaNilmZT3BlbkFJxAlW57CiKjgdiaiHIJrG"
CONFIG_LLM = [{"model": "gpt-3.5-turbo", "api_key": key}]
LLM_CONFIG = {
    # Generate functions config for the Tool
    "functions": [
        generate_llm_config(network_scanTool),
        generate_llm_config(port_scanTool),
        generate_llm_config(web_scanTool),
        generate_llm_config(scanTool),
        generate_llm_config(msfconsoleTool),
        generate_llm_config(searchMatchingModulesTool),

        generate_llm_config(moduleTool),
        generate_llm_config(attackTool),
        generate_llm_config(meterpreter)
    ],
    "config_list": CONFIG_LLM,  # Assuming you have this defined elsewhere
    # "timeout": 240,
}
LLM_CONFIG_MSF = {
    # Generate functions config for the Tool
    "functions": [
        generate_llm_config(network_scanTool),
        generate_llm_config(scanTool),
        generate_llm_config(searchMatchingModulesTool),
        generate_llm_config(moduleTool),
        generate_llm_config(attackTool),
        generate_llm_config(meterpreter),
    ],
    "config_list": CONFIG_LLM,  # Assuming you have this defined elsewhere
    "timeout": 240,
}

LLM_CONFIG_RAG ={ "functions": [
    generate_llm_config(retrieve_tool)
    ],
    "config_list": CONFIG_LLM,  # Assuming you have this defined elsewhere
    "timeout": 240,
}
LLM_CONFIG_DEFAULT = {
    "config_list": CONFIG_LLM,  # Assuming you have this defined elsewhere
    "timeout": 240,
}




