from typing import List, Dict, Union

from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent
from langchain_community.vectorstores import ElasticsearchStore
from langchain_core.documents import Document

from contant.ESContant import es_url, index_name, embeddings


class MyRetrieveUserProxyAgent(RetrieveUserProxyAgent):

    def query_vector_db(
            self,
            query_texts: List[str],
            n_results: int = 10,
            search_string: str = "",
            **kwargs,
    ) -> list[Document]:
        # define your own query function here
        # 初始化ES客户端
        vectorstore = ElasticsearchStore(
            es_url=es_url, index_name=index_name, embedding=embeddings
        )
        # 构建查询文本和过滤器
        query_texts_combined = " ".join(query_texts)
        filter_list = [{"term": {"content": search_string}}] if search_string else None
        return vectorstore.similarity_search(query_texts_combined, k=n_results, filter=filter_list)

    def retrieve_docs(self, problem: str, n_results: int = 20, search_string: str = "", **kwargs):
        results = self.query_vector_db(
            query_texts=[problem],
            n_results=n_results,
            search_string=search_string,
            **kwargs,
        )
        self._results = results

    def _get_context(self, results: list[Document]) -> str:
        context_str = "\n".join(doc.page_content for doc in results)
        return context_str
