import json

from langchain.text_splitter import RecursiveCharacterTextSplitter


# 文本的json解析
class JsonLoader:
    def __init__(self, file_path):
        self.file_path = file_path

    def load(self):
        with open(self.file_path, 'r',encoding='UTF-8') as file:
            data_str = file.read()
            data = json.loads(data_str)
        return data

json_file_path = 'D:\workplace\Agent-main\es\识别IP方法.json'
loader = JsonLoader(json_file_path)
document_list = loader.load()
print(f"Successfully loaded {len(document_list)} documents")
metadata = []
content = []
for doc in document_list:
        content.append(doc["question"])
        metadata.append({
            "answer": doc["answer"]
        })
        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
            chunk_size=512,
            chunk_overlap=256,
        )
        docs = text_splitter.create_documents(content, metadatas=metadata)

if __name__ == '__main__':
    json_file_path = 'D:\workplace\Agent-main\es\识别IP方法.json'
    loader = JsonLoader(json_file_path)
    document_list = loader.load()
    print(f"Successfully loaded {len(document_list)} documents")
    metadata = []
    content = []
    for doc in document_list:
        content.append(doc["question"])
        metadata.append({
            "answer": doc["answer"]
        })
        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
            chunk_size=512,
            chunk_overlap=256,
        )
        docs = text_splitter.create_documents(content, metadatas=metadata)

        print(f"Split {len(document_list)} documents into {len(docs)} passages")
        print(docs)
